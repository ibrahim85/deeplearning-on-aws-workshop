{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass logistic regression\n",
    "\n",
    "아래 예제는 손으로 쓴 숫자를 Image classfication을 통해 구분하는 예제입니다.\n",
    "![png](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/example/mnist.png) \n",
    "Multiclass logistic regression (또는 softmax regression, multinomial regression) 을 통해 숫자를 구분하는 모델을 실습하겠습니다. 필요한 Library를 Import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 모델링 연산을 CPU만을 사용할지, GPU를 활용(mx.gpu(0))할지 선택하는 옵션입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "잘 알려진 Dataset인 MNIST dataset은 28x28 의 흑백으로 손으로 그려진 숫자 이미지를 제공합니다. 0에서 9의 숫자들을로 이루어져 있습니다. 우선은 MXNet 기능을 활용하여 Dataset을 가져옵니다. 가져온 이미지를 float [0,1]로 변환합니다. \n",
    "\n",
    "MNIST dataset detail: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/datasets/train-images-idx3-ubyte.gz from http://data.mxnet.io/data/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading /home/ec2-user/.mxnet/datasets/train-labels-idx1-ubyte.gz from http://data.mxnet.io/data/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading /home/ec2-user/.mxnet/datasets/t10k-images-idx3-ubyte.gz from http://data.mxnet.io/data/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading /home/ec2-user/.mxnet/datasets/t10k-labels-idx1-ubyte.gz from http://data.mxnet.io/data/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "mnist_train = mx.gluon.data.vision.MNIST(train=True, transform=transform)\n",
    "mnist_test = mx.gluon.data.vision.MNIST(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset은 Training 용도와 Testing 용도로 구분합니다. 각 데이터 하나는 image와 label를 가집니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28L, 28L, 1L) 5.0\n"
     ]
    }
   ],
   "source": [
    "image, label = mnist_train[0]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가로 이 이미지 하나는 (channel, height, width)의 세가지 속성을 가지고, 만약 컬러 이미지라면 channel은 (red, green, and blue) 의 dimension을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record the data and label shapes\n",
    "\n",
    "input 값과 output 값의 개수를 정의합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning 라이브러리는 일반적으로 (batch, channel, height, width)정보를 이미지에서 찾습니다. 그러나, 대부분 시작화를 하기 위한 라이브러리는 (height, width, channel)을 선호합니다. 아래에서 속성을 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28L, 28L, 3L)\n"
     ]
    }
   ],
   "source": [
    "im = mx.nd.tile(image, (1,1,3))\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경하고나면 image를 시각화하여 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBPUf/Iqa+Y/vp7oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7066f6ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im.asnumpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 5를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data iterator\n",
    "\n",
    "이제 이미지 데이터들을 iterator에 읽어드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data = mx.gluon.data.DataLoader(mnist_train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test를 위한 이미지 데이터 역시 읽어드립니다. 후에 생성된 모델에 테스트 데이터를 이용하여 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = mx.gluon.data.DataLoader(mnist_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate model parameters\n",
    "\n",
    "이제 모델을 정의합니다. 이번 랩에서는 Multimodal 구조를 사용하지는 않으며, 단순히 각각의 이미지를 single ID vector로 만듭니다. 28x28 = 784 의 경우의 수가 나옵니다. \n",
    "\n",
    "Multiclass classfication 모델을 이용하므로, 입력된 이미지에 대해서 probability 를 추가합니다. 그렇게 하기 위해서는 각 클래스마다 784 wegihts를 가지는 별도의 vector가 하나 필요합니다. 10개의 class가 있으므로, 784 by 10 matrix를 가지게 됩니다.\n",
    "\n",
    "그리고, 각각의 결과마다 하나의 offset을 추가합니다. 이것을 *bias term*으로 정의합니다. 그리고 그것을 10-dimensional array ``b``에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = nd.random_normal(shape=(num_inputs, num_outputs))\n",
    "b = nd.random_normal(shape=num_outputs)\n",
    "\n",
    "params = [W, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MXNet이 트레이닝 중에 각 파라미터에 대해서 gradients 를 가지도록 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass logistic regression\n",
    "\n",
    "앞서 진행한 Linear regression 랩에서 결과값으로 *yhat*을 정의했었습니다. 그리고 최대한 실제 *y*값에 가깝도록 학습을 하였습니다. 이번에는 *classification*을 목적으로하여, 입력값인 *X*가 특정 *L* 클래스에 할당되는 것을 수행합니다.\n",
    "\n",
    "설명한 것과 같이 기본적인 생각은 입력값 *X*을 10개의 다른 값으로 구분하여 결과값 ``y_linear``에 저장합니다. 그리고 이 결과값을 normalize합니다. 이 normalization 은 결과값이 양수로 처리되며 결과값 yhat으로 맞는 probability로 인식할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition =nd.sum(exp, axis=0, exclude=True).reshape((-1,1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.01466005  0.03104205  0.09487285  0.11615293  0.07316667  0.01516553\n",
      "   0.44094777  0.08199082  0.0917872   0.04021411]\n",
      " [ 0.0309542   0.07588483  0.37230074  0.03313261  0.0499984   0.13276106\n",
      "   0.14566724  0.02354518  0.08515968  0.05059606]]\n",
      "<NDArray 2x10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "sample_y_linear = nd.random_normal(shape=(2,10))\n",
    "sample_yhat = softmax(sample_y_linear)\n",
    "print(sample_yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 결과값의 합이 1인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1.  1.]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(nd.sum(sample_yhat, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약간의 차이는 있으나, 정상적으로 동작을 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "이제 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    y_linear = nd.dot(X, W) + b\n",
    "    yhat = softmax(y_linear)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  cross-entropy loss function\n",
    "\n",
    "트레이닝을 시작하기전에, Loss function을 정의합니다. 여기서는 cross-entropy loss function 을 정의하여 사용합니다. Deep Learning에서 가장 많이 사용되는 Loss function 중 하나입니다. 일반적인 regression 보다 classification이 보다 많이 사용되기 때문입니다. \n",
    "\n",
    "기본적인 접근은 타겟 값인 Y는 10개 중 하나가 1인 vector값을 가집니다. 예를 들어 ``[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]``와 같은 값을 가집니다. 만약 이를 Label 2라 한다면, cross-entropy loss는 Y값이 Label 2에 속하는 값에 대해서만 Probability를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(yhat, y):\n",
    "    return - nd.sum(y * nd.log(yhat), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Linear regression에서 사용한 SGD(Stochastic gradient descent)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(params, lr):    \n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write evaluation loop to calculate accuracy\n",
    "\n",
    "cross-entropy가 유용하긴 하지만 보통 사람들은 정확도를 생각할 때 전체 질문에 몇 개를 맞췄는지에 대해서 Performance를 생각합니다. 따라서 Accuracy를 생각할 떄 아래는 evaluation loop에서 각 Iterator, network, 전체 Dataset에 대해서 계산된 평균 accuracy를 고려합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1,784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당연하겠지만, 어떤 입력값이든 10개의 클래스 중에 하나에 포함되게 되므로, 기본적으로 0.10 의 accurary는 가져야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_accuracy(test_data, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "moving_loss = 0.\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1,784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0)) \n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "            \n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "약 90% 정확도를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
