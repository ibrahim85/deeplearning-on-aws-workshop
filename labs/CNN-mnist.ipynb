{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network 실습\n",
    "\n",
    "## 손으로 쓴 숫자 인식 (Handwritten Digit Recognition)\n",
    "\n",
    "손으로 쓴 숫자를 모아 놓은 [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset을 학습해서 손으로 쓴 숫자가 어떤 숫자인지를 분류하는 deep learning 모델을 작성하는 법을 배웁니다. 이 예제는 Deep Learning에서는 \"Hello World\" 같은 것입니다.\n",
    "\n",
    "> MNIST는 손으로 쓴 숫자를 모아 놓은 데이터입니다. 28x28 픽셀의 회식 이미지를 70,000개의 숫자가 10개의 클래스로 구분되어 있습니다.\n",
    "> ![png](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/example/mnist.png)\n",
    ">\n",
    "> **Figure 1:** Sample images from the MNIST dataset.\n",
    "\n",
    "이 예제에서는 60,000개를 학습 이미지로 사용하고, 10,000개를 테스트 이미지로 사용합니다. 이 실습에서는 아래 두가지 방법으로 숫자 분류 모델을 만들어 보겠습니다.\n",
    "\n",
    "* Multilayer Perceptron (MLP)\n",
    "* Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩\n",
    "\n",
    "모델을 정의하기 전에 [MNIST](http://yann.lecun.com/exdb/mnist/) dataset을 로딩합니다. 아래 코드는 이미지 데이터셋을 다운로드해서, 이미지와 레벨을 메모리에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 수행하면, MNIST 데이터셋 전체가 메모리로 올라갑니다. 만약, 데이터셋이 더 큰 경우에는 모든 데이터셋을 메모리에 미리 올리는 것인 불가능할 것입니다. 이를 해결하기 위해서는 데이터 소스로부터 빠르고 효과적으로 데이터를 스트리밍할 수 있는 방법이 필요한데, MXNet Data iterator들이 이런 기능을 제공합니다. 이 iterator들은 초기화가 쉽고, 속도 최적화가 되어 있습니다. 학습이 수행되는 동안, 학습 데이터는 작은 배치로 나뉘어서 사용되고, 각 학습 샘플들은 전체 학습이 종료될 때까지 몇차례 재사용됩니다.\n",
    "\n",
    "이 실습에서는 data iterator를 한 배치에 100개의 데이터에 사용되도록 설정합니다. 각 샘플은 28x28 픽셀의 회색 이미지와 어떤 숫자인지를 알려주는 라벨로 구성되어 있습니다.\n",
    "\n",
    "이미지 배치는 보통 4차원 행렬로 표현됩니다. 이 행렬의 shape는 `(batch_size, num_channels, width, height)` 입니다. MNIST 이미지가 회색이기 때문에, 색깔 채널은 한개입니다. 즉, 입력의 shape는 `(batch_size, 1, 28, 28)`이 됩니다.\n",
    "\n",
    "학습 데이터를 사용하는데 중요한 점은, 라벨 순서대로 나열된 데이터를 그대로 사용하지 말아야된다는 것입니다. 만약 같은 라벨의 데이터를 묶어서 학습한다면 학습 속도가 느려집니다. Data iterator는 입력 데이터를 자동으로 섞어줍니다. 테스트 데이터는 섞을 필요 없습니다.\n",
    "\n",
    "아래 코드는 data iterator들은 초기화해서, 학습 데이터와 테스트 데이터를 주는 iterator를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습\n",
    "\n",
    "MNIST 데이터를 학습해서 모델은 만드는 다양한 방법 중에, \n",
    "\n",
    "(1) 전통적인 deep neural network 아키텍처, Multilayer Percepton (MLP),\n",
    "\n",
    "(2) Convolutional Neural Network 아키텍처\n",
    "\n",
    "를 어떻게 구성하는지 알아보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 1 - [Multilayer Perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) \n",
    "\n",
    "MXNet의 Symbol API를 이용해서 MLP를 정의합니다. 우선 입력 데이터를 저장할 place holder를 생성합니다. MLP를 다룰때는, 28x28 이미지를 784 ( 28 * 28 ) 크기의 1차원 행렬로 변환해서 사용해야 합니다. 1차원으로 펼칠 때 원소들의 순서는 모든 이미지에 동일하게 적용된다면 펼치는 순서는 중요하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 pre-prosessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "# Flatten the data from 4-D shape into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.flatten(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다차원 배열을 flat하게 만들면서 중요한 정보가 손실되는 것이 아닐까요? 사실 그렇습니다. 이에 대해서는 입력 데이터의 모양을 보존하는 Convolutional Neural Network을 만들때 살펴보겠습니다. 우선은 flat한 이미지를 이용하겠습니다.\n",
    "\n",
    "MLP는 몇개의 fully connected layer들로 구성됩니다. Fully connected layer (FC layer)는 각 neuron이 이전 layer의 모든 neuron들과 연결되어 있습니다. 선형대수 관점에서 보면, 하나의 FC layer는 *n x m* 입력 행렬 *X*에 [affine transform](https://en.wikipedia.org/wiki/Affine_transformation)을 적용해서, *n x k* 행렬 *Y*를 얻는 것을 의미합니다. 여기서 *k*는 FC layer의 neuron 개수를 의미합니다. FC layer는 아래 두개의 학습 파라메터를 갖습니다.\n",
    "\n",
    "* *m x k* weight 행렬 *W*\n",
    "* *m x 1* bias 백터 *b*\n",
    "\n",
    "##### Activation 함수의 중요성\n",
    "MLP에서 대부분의 FC layer는 activation 함수 연결됩니다. Activation 함수를 적용함으로 element-wise non-linearity를 갖게됩니다. 만약 없다면, 여러 FC layer들은 하나의 FC layer로 동작하게됩니다. 많이 사용되는 activation 함수는 [rectified linear unit](https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29) (ReLU), tanh 또는 sigmoid가 있습니다. 대부분의 경우 좋은 성능을 보여주는 ReLu를 많이 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 네트워크 정의\n",
    "\n",
    "#### Fully Connected (128) --> ReLu --> Fully Connected (64) --> ReLu\n",
    "\n",
    "다음 코드는 128개와 64개의 neuron을 갖는 Fully Connected layer 두개를 정의합니다. 이 두 FC layer 사이에는 ReLu activation를 적용합니다.\n",
    "\n",
    "##### <font color='red'>문제</font>\n",
    "* 첫번째 레이어에 activation 함수를 ReLu (relu)로 설정\n",
    "* Neuron 개수가 다른 두번쨰 Fully-connected layer (activation 함수 포함) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = ___ 두번째 레이어의 Fully Connected layer 정의 ___\n",
    "act2 = ___ 두번째 레이어의 Activation 함수 적용 ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 Fully Connected layer는 결과 클래스 개수와 같은 수의 neuron을 갖도록 정의합니다. 이 layer에 대한 activation 함수는 softmax 함수를 사용합니다.\n",
    "\n",
    "###### softmax 함수\n",
    "softmax 함수는 입력값들을 각 클래스에 대한 확률값으로 변환합니다. \n",
    "\n",
    "###### loss 함수\n",
    "loss 함수는 네트워크가 예측한 확률 분포 (예, softmax output)과 라벨의 실제 확률 분포 사이의 [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy)를 계산합니다.\n",
    "\n",
    "아래 코드는 마지막 크기가 10인 fully connected layer를 정의하고, 그 결과를  `SoftMaxOutput` layer로 연결합니다. 이 layer는 softmax과 cross-entropy loss를 동시에 계산합니다. loss는 학습 단계에서만 계산됩니다.\n",
    "\n",
    "\n",
    "> <font color='red'>문제</font>\n",
    "* 마지막 layer인 fc3에 몇개의 neuron이 필요한가요? 해당 숫자를 num_hidden 값으로 설정하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST has 10 classes\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden=__Neuron 개수__)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mlp_mnist.png)\n",
    "\n",
    "**Figure 2:** MLP network architecture for MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 수행\n",
    "\n",
    "`module`의 high-level API를 이용해서 학습(training) 및 예측(inference)을 수행하는 코드를 작성합니다. `module` API는 학습을 어떻게 진행할 것인지 정하는 파라메터(hyper-parameter)를 설정할 수 있습니다.\n",
    "\n",
    "* optimizer: SGD (Stochastic Gradient Descent)\n",
    "* batch_size: 100\n",
    "* learning_rate: 0.1\n",
    "* epoch: 10\n",
    "\n",
    "> **Standard SGD vs. mini-batch SGD**\n",
    "> \n",
    "> Standard SGD : 하나의 데이터씩 학습을 수행함. 학습 속도가 느림\n",
    "> mini-batch SGD : 전체 학습 데이터를 작은 집합 (batch)로 나눠서 mini-batch 단위로 학습을 수행함\n",
    "\n",
    "> epoch: 학습 데이터 전체에 대한 수행 회수\n",
    "\n",
    "학습은 최적의 파라메터(weight + bias)를 찾을 떄까지 학습 데이터에 대해서 반복적으로 수행합니다. 최적의 파라메터가 찾아졌는지 여부는 모델의 성능(정확도)가 수렴 여부를 보고 결정하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\n",
    "# create a trainable module on CPU\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='sgd',  # use SGD to train\n",
    "              optimizer_params={'learning_rate':0.1},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches\n",
    "              num_epoch=10)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 (Prediction)\n",
    "\n",
    "학습이 완료되면, 테스트 데이터를 사용해서 예측을 수행하고 이를 기반으로 학습 모델을 평가합니다.\n",
    "\n",
    "아래 코드는 각 테스트 이미지에 대한 예측 확률 점수(prediction probability score)를 계산합니다.\n",
    "\n",
    "*prob[i][j]* : *i*-번째 테스트 이미지가 *j*-번째 결과 클래스일 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = mlp_model.predict(test_iter)\n",
    "assert prob.shape == (10000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 이미지에 대한 라벨 정보가 있기 때문에, accuracy metric을 다음과 같이 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 수행되었다만, accuracy 값이 0.96 정도로 나올것입니다. 이는, 숫자를 정확하게 맞출 확률이 96%라는 의미입니다. 다음 방법을 사용하면, 더 좋을 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "MLP를 이용해서 이미지를 분류하는 경우에는 이미지의 원래 모양을 고려하지 때문에, 가로축과 세로축을 따르는 공간적인 상관 관계에 대한 의미를 살려서 분석하지 못합니다. Convolutional Neural Network (CNN)은 이 문제를 더 구조화된 weight 구성을 통해서 해결합니다. 즉, 이미지를 1차원 배열로 변환해서 간단한 형렬 곱하기 연산을 수행하는 대신, 입력 이미지에 대한 2차원 convolution을 수행하는 여러개의 convolutional layer를 사용합니다.\n",
    "\n",
    "#### Convolution Layer\n",
    "하나의 convolution layer는 하나 이상의 filter를 갖습니다. 각 filter는 feature를 탐지하는 역할을 하는 filter들은 학습을 통해서 filter에 사용되는 적절한 파라메터를 찾아나가게 됩니다.\n",
    "\n",
    "MLP와 유사하게 convolution layer의 결과는 non-linearity가 activation 함수를 통해서 적용되기도 합니다.\n",
    "\n",
    "#### Pooling Layer\n",
    "CNN의 또다른 중요한 레이어는 pooling layer입니다. A pooling layer serves to make the CNN translation invariant: a digit remains the same even when it is shifted left/right/up/down by a few pixels. pooling layer는 또한 *n x m* 패치를 단일 값으로 줄임으로 네트워크가 공간적인 위치에 덜 민감하도록 만드는 역할을 합니다.\n",
    "\n",
    "Pooling layer는 늘 convolution (+activation) layer 다음에 위치합니다.\n",
    "\n",
    "* conv layer --> activation layer --> pooling layer\n",
    "* conv layer --> pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드는 LeNet이라는 Convolutional Neural Network 아키텍처를 정의합니다.\n",
    "\n",
    "> LeNet: 숫자 분류에 대한 성능이 좋은 유명한 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='red'>문제</font>\n",
    "> LeNet은 activation 함수로 sigmoid를 사용했지만, 여기서는 tanh activation 함수를 사용하겠습니다. act_type 값을 변경해보세요. (힌트: tanh )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"sigmoid\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"sigmoid\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"sigmoid\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/conv_mnist.png)\n",
    "\n",
    "**Figure 3:** First conv + pooling layer in LeNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 MLP에서 사용한 hyper-parameter 값을 동일하게 LeNet에 적용하는 코드입니다. \n",
    "\n",
    ">  <font color='red'>문제</font>\n",
    "아래 코드를 GPU를 사용하도록 변경해보세요. (힌트, mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a trainable module on GPU 0\n",
    "\n",
    "accu = []\n",
    "def my_callback(param):\n",
    "    _, value = param.eval_metric.get()\n",
    "    accu.append(value)\n",
    "\n",
    "lenet_model = mx.mod.Module(symbol=lenet, context=mx.cpu())\n",
    "# train with the same\n",
    "lenet_model.fit(train_iter,\n",
    "                eval_data=val_iter,\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.1},\n",
    "                eval_metric='acc',\n",
    "                batch_end_callback = [mx.callback.Speedometer(batch_size, 100),my_callback],\n",
    "                num_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(accu)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate = 0.1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 (Prediction)\n",
    "\n",
    "학습이 완료된 LeNet 모델에 테스트 데이터를 이용해서 모델 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], None, batch_size)\n",
    "prob = lenet_model.predict(test_iter)\n",
    "test_iter = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)\n",
    "# predict accuracy for lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(test_iter, acc)\n",
    "print(acc)\n",
    "assert acc.get()[1] > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet 모델의 성능(정확도)가 MLP의 성능보다 좋은 것을 볼 수 있습니다. "
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
