{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Apache MXNet Basic 실습\n",
    "## Module - Neural network training and inference\n",
    "\n",
    "학습 수행 순서학습 \n",
    "* 데이터 입력\n",
    "* 모델 파라메터 초기화\n",
    "* 네트워크를 따라 Forward, Backward 수행\n",
    "* Gradient들을 기반으로 weight 값 조정\n",
    "* 모델 체크포인트\n",
    "\n",
    "Luckily, MXNet modularizes commonly used code for training and inference in\n",
    "the `module` (`mod` for short) package. `Module` provides both high-level and\n",
    "intermediate-level interfaces for executing predefined networks. One can use\n",
    "both interfaces interchangeably. We will show the usage of both interfaces in\n",
    "this tutorial.\n",
    "\n",
    "\n",
    "## Preliminary\n",
    "\n",
    "이번 실습은 [UCI letter recognition](https://archive.ics.uci.edu/ml/datasets/letter+recognition) dataset을 대상으로 [Multilayer Perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP) 네트워크를 학습을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. 학습, 검증 데이터 준비\n",
    "\n",
    "* Dataset을 다운로드하고 80:20 비율료 학습:테스트 데이터로 나눔\n",
    "* training data iterator를 초기화해서 32개의 배치 샘플을 주도록 설정함\n",
    "* 테스트 데이터를 위한 별도의 iterator 생성\n",
    "\n",
    "> <font color='red'>문제</font>\n",
    "1. 아래 코드는 학습:테스트 데이터가 5:5 비율로 되어 있습니다. 80:20 비율이 되도록 코드를 변경해보세요. (힌트: ntrain에 할당되는 값에 곱해지는 비율 변경)\n",
    "2. 아래 코드는 batch 크기가 1로 되어 있습니다. 코드를 변경해서 batch 크기가 32가 되도록해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "fname = mx.test_utils.download('http://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data')\n",
    "data = np.genfromtxt(fname, delimiter=',')[:,1:]\n",
    "label = np.array([ord(l.split(',')[0])-ord('A') for l in open(fname, 'r')])\n",
    "\n",
    "batch_size = 1\n",
    "ntrain = int(data.shape[0]*0.5)\n",
    "train_iter = mx.io.NDArrayIter(data[:ntrain, :], label[:ntrain], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(data[ntrain:, :], label[ntrain:], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. 네트워크 정의\n",
    "\n",
    "1) 첫번째 레이어(hidden layer)는 64개의 neuron을 갖는 fully-connected로 정의\n",
    "\n",
    "2) 첫번째 레이어의 각 neuron에 relu activation 함수를 적용\n",
    "\n",
    "3) 두번째 레이어(output layer)에는 26개의 neuron을 갖는 fully-connected로 정의\n",
    "\n",
    "4) 두번째 레이어에는 multi classification을 위한 softmax 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = mx.sym.Variable('data')\n",
    "net = mx.sym.FullyConnected(net, name='fc1', num_hidden=64)\n",
    "net = mx.sym.Activation(net, name='relu1', act_type=\"relu\")\n",
    "net = mx.sym.FullyConnected(net, name='fc2', num_hidden=26)\n",
    "net = mx.sym.SoftmaxOutput(net, name='softmax')\n",
    "mx.viz.plot_network(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Module 생성\n",
    "\n",
    "Module 생성은 `Module` 클래스를 사용하며, 다음과 같은 파라메터가 있음:\n",
    "\n",
    "- `symbol`: Neural Network 정의\n",
    "- `context`: 어떤 디바이스에서 수행할 것인지 (CPU, GPU, 여러 GPU들)\n",
    "- `data_names` : 입력 데이터 변수 이름들\n",
    "- `label_names` : 입력 label 변수 이름들\n",
    "\n",
    "이 예제에서는 `data`라는 이름의 한개의 데이터를 사용하고, label은 `softwas_label`이라는 이름을 사용합니다. `softmax_label`은 `SoftmaxOutput` 연산 이름에서 자동으로 부여된 이름입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=net,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4-1 중간 레벨 인터페이스(Intermediate-level Interface)를 이용한 학습 수행\n",
    "\n",
    "중간 레벨 인터페이스를 사용해서 모델을 학습 시키는 순서는 다음과 같습니다.\n",
    "\n",
    "- `bind` : 메모리를 할당해서 연산 환경을 준비\n",
    "- `init_params` : 파레메터 할당 및 초기화\n",
    "- `init_optimizer` : optimizer 초기화 (기본 optimizer는 `sgd`)\n",
    "- `metric.create` : 입력 metric 이름을 사용해서 평가 metric 생성\n",
    "- `forward` : Forward 계산 수행\n",
    "- `update_metric` : 마지막 forward 계산 결과를 바탕으로 평가 metric 업데이트 (Evaluates and accumulates)\n",
    "- `backward` : Backward 계산 수행\n",
    "- `update` : 위에서 설정된 optimizer와 마지막으로 계산된 forward-backward 배치 결과를 기반으로 파라메터들을 업데이트함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# allocate memory given the input data and label shapes\n",
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params(initializer=mx.init.Uniform(scale=.1))\n",
    "# use SGD with learning rate 0.1 to train\n",
    "mod.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.1), ))\n",
    "# use accuracy as the metric\n",
    "metric = mx.metric.create('acc')\n",
    "# train 5 epochs, i.e. going over the data iter one pass\n",
    "for epoch in range(8):\n",
    "    train_iter.reset()\n",
    "    metric.reset()\n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch, is_train=True)       # compute predictions\n",
    "        mod.update_metric(metric, batch.label)  # accumulate prediction accuracy\n",
    "        mod.backward()                          # compute gradients\n",
    "        mod.update()                            # update parameters\n",
    "    print('Epoch %d, Training %s' % (epoch, metric.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To learn more about these APIs, visit [Module API](http://mxnet.io/api/python/module.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4-2 상위 레벨 인터패이스 (High-level Interface)를 이용한 학습, 예측\n",
    "\n",
    "### 학습\n",
    "\n",
    "[fit API](http://mxnet.io/api/python/module.html#mxnet.module.BaseModule.fit) 하나를 호출하면, 위 과정들이 자동으로 수행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reset train_iter to the beginning\n",
    "train_iter.reset()\n",
    "\n",
    "# create a module\n",
    "mod = mx.mod.Module(symbol=net,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label'])\n",
    "\n",
    "# fit the module\n",
    "mod.fit(train_iter,\n",
    "        eval_data=val_iter,\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.1},\n",
    "        eval_metric='acc',\n",
    "        num_epoch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By default, `fit` function has `eval_metric` set to `accuracy`, `optimizer` to `sgd`\n",
    "and optimizer_params to `(('learning_rate', 0.01),)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 예측 및 평가 (Predict and Evaluate)\n",
    "\n",
    "`predict()`를 사용해서 예측을 수행합니다. 이 함수는 모든 예측 결과를 수집해서 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = mod.predict(val_iter)\n",
    "assert y.shape == (4000, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "만약 예측 결과는 필요없고 테스트 데이터를 사용해서 학습된 모델을 평가만 필요하면 `score()` 함수를 이용할 수 있습니다. 이 함수는 input validation dataset을 대상으로 예측값을 계산하고, 정의된 input metric을 사용해서 모델의 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score = mod.score(val_iter, ['acc'])\n",
    "print(\"Accuracy score is %f\" % (score[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "평가를 위한 다른 metric으로는 `top_k_acc`(top-k-accuracy),\n",
    "`F1`, `RMSE`, `MSE`, `MAE`, `ce`(CrossEntropy) 등이 있습니다. 자세한 내용은 [Evaluation metric](http://mxnet.io/api/python/metric.html) 참고하세요.\n",
    "\n",
    "> <font color='red'>문제</font>\n",
    "학습 반복 획수(epoch), 학습 속도(learning_rate), 최적화 파라메터를 변경하면서 score 값이 어떻게 바뀌는지 살펴보고, 최적의 score를 얻는 설정을 찾아보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. 학습 모델 저장\n",
    "\n",
    "학습 epoch 마다 checkpoint callback을 사용해서 module 파라메터들을 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# construct a callback function to save checkpoints\n",
    "model_prefix = 'mx_mlp'\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "\n",
    "mod = mx.mod.Module(symbol=net)\n",
    "mod.fit(train_iter, num_epoch=5, epoch_end_callback=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> <font color='red'>문제</font>\n",
    "저장된 symbol 파일 내용을 확인해보세요.\n",
    "\n",
    "> 1) !ls (Windows는 dir)로 파일 이름 확인 (mx_mlp-symbol.json)\n",
    ">\n",
    "> 2) cat (Windows는 type) 으로 파일 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!cat ___symbol 파일 이름____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. 저당된 학습 모델  읽기\n",
    "\n",
    "저장된 module parameter를 읽어서 사용하기 위해서 `load_checkpoint` 함수를 사용해서 저장된 module parameter를 읽을 수 있습니다. 이 함수는 Symbol과 그와 연관된 파라메터를 읽어 들입니다. 이 파라메터는 module에 설정해서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, 3)\n",
    "assert sym.tojson() == net.tojson()\n",
    "\n",
    "# assign the loaded parameters to the module\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "만약, 저장된 체크포인트에 이어서 학습을 계속 수행하고 싶으면 `set_params()`를 사용하는 대신 `fit()` 함수를 사용합니다. 이렇게 하면, 파라메터들을 초기화하지 않고 학습을 재시작하고, `begin_epoch` 변수를 사용하면 마지막 저장된 epoch부터 재시작한다는 것을 알릴 수 있습니다. 만약 저장된 파라메터가 epoch 2에서 였다면, begin_epoch는 3으로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=sym)\n",
    "mod.fit(train_iter,\n",
    "        num_epoch=8,\n",
    "        arg_params=arg_params,\n",
    "        aux_params=aux_params,\n",
    "        begin_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
