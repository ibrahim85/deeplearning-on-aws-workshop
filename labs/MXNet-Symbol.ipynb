{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Apache MXNet Basic 실습\n",
    "## Symbol - Neural network graphs와 자동 미분(auto-differentiation)\n",
    "\n",
    "* Symbol은 이용한 선언형(declarative) 프로그래밍 방법은,\n",
    "\n",
    "    1. 입력과 출력에 대한 Placeholder을 포함한 연산 그래프 정의\n",
    "    2. NDArray 변수들을 Placeholder에 바인딩한 후, 그래프 연산을 계산\n",
    "\n",
    "\n",
    "* 최적화된 연산 수행 (예, 메모리 재사용을 통한 적은 메모리 사용)\n",
    "\n",
    "> 참조 사이트\n",
    ">\n",
    "> [MXNet How To](http://mxnet.io/how_to/index.html)\n",
    ">\n",
    "> [MXNet Architecture](http://mxnet.io/architecture/index.html)\n",
    ">\n",
    "> [a more thorough discussion on the comparative strengths of imperative and symbolic programing](http://mxnet.io/architecture/program_model.html)\n",
    "> \n",
    "> [Symbolic Configuration and Execution in Pictures](http://mxnet.io/api/python/symbol_in_pictures.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 기본 Symbol 조합\n",
    "\n",
    "### <font color='red'>기본 연산들</font>\n",
    "\n",
    "아래 예제는 간단한 그래프 연산 `a + b` 을 정의합니다. 우선, `mx.sym.Variable`를 이용해서 placeholder 두개를 정의하고, `+` 연산부호로 원하는 symbol을 정의합니다. 각 placeholder에는 a,b라는 이름을 정하지만, 정하지 않을 경우에는 MXNet이 임의로 이름을 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "a = mx.sym.Variable('a')\n",
    "b = mx.sym.Variable('b')\n",
    "c = a + b\n",
    "(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`NDArray`에서 지원하는 대부분의 연산들은 `Symbol`에서도 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# elemental wise multiplication\n",
    "d = a * b\n",
    "# matrix multiplication\n",
    "e = mx.sym.dot(a, b)\n",
    "# reshape\n",
    "f = mx.sym.reshape(d+e, shape=(1,4))\n",
    "# broadcast\n",
    "g = mx.sym.broadcast_to(f, shape=(2,4))\n",
    "# plot\n",
    "mx.viz.plot_network(symbol=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "위 예제들에서 정의된 연산 그래프들은 `bind` 함수를 통해서 실제로 사용할 입력 데이터를 적용하여 그래프 연산을 수행할 수 있습니다. 예제는 아래 `데이터 연결 및 수행`에서 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color='red'>기본 Neural Networks</font>\n",
    "\n",
    "기본 연산외에, `Symbol`을 사용해서 다양한 Neural Network 래이어들을 정의할 수 있습니다. 다음 예제는 2-layer fully connected neural를 Symbol을 사용해서 정의해봅니다. 이렇게 정의된 neural network는 mx.viz.plot_network를 이용해서 시각화할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = mx.sym.Variable('data')\n",
    "net = mx.sym.FullyConnected(data=net, name='fc1', num_hidden=128)\n",
    "net = mx.sym.Activation(data=net, name='relu1', act_type=\"relu\")\n",
    "net = mx.sym.FullyConnected(data=net, name='fc2', num_hidden=10)\n",
    "net = mx.sym.SoftmaxOutput(data=net, name='out')\n",
    "mx.viz.plot_network(net, shape={'data':(100,200)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "각 symbol은 고유한 문자열로 구성된 이름을 갖습니다. NDArray와 Symbol은 하나의 tensor (다차원 행렬)를 의미하며, **연산자**는 tensor들간의 연산을 정의합니다. 연잔자는 Symbol 또는 NDArray를 입력으로 받으며, hidden neuron 개수 (*num_hidden*)이나 activation type (*act_type*) 등과 같은 **hyperparameter**들을 입력받습니다.\n",
    "\n",
    "Symbol을 여러 argument들을 받는 함수로 생각할 수도 있습니다. 이 argument들은 다음 함수를 통해서 조회할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "위 argument들은 각 symbol에 필요한 파라메터와 입력들로 각 의미는 아래와 같습니다.\n",
    "\n",
    "- *data*: *data* 변수에 필요한 입력 데이터\n",
    "- *fc1_weight*와 *fc1_bias*: 첫번째 fully connected layer *fc1*에서 사용되는 weight와 bias\n",
    "- *fc2_weight*와 *fc2_bias*: 두번째 fully connected layer *fc1*에서 사용되는 weight와 bias\n",
    "- *out_label*: loss에 필요한 label\n",
    "\n",
    "임의로 할당되는 이름 대신에, 각 argument에 이름을 명시적으로 할당하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = mx.symbol.Variable('data')\n",
    "w = mx.symbol.Variable('myweight')\n",
    "net = mx.symbol.FullyConnected(data=net, weight=w, name='fc1', num_hidden=128)\n",
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <font color='red'>복잡한 조합</font>\n",
    "\n",
    "MXNet은 deep learning에서 일반적으로 사용되는 레이어들에 대한 최적화된 symbol들을 제공합니다. 다음 예제는 두 symbol을 정의하고 element-wise 합을 계산하고, 128개 hidden neuron들을 갖는 fully-connected layer를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lhs = mx.symbol.Variable('data1')\n",
    "rhs = mx.symbol.Variable('data2')\n",
    "net = mx.symbol.FullyConnected(data=lhs + rhs, name='fc1', num_hidden=128)\n",
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "위 예제는 Single forward 조합을 하고 있지만, 보다 복잡한 조합도 가능합니다. 다음 예제는 두개의 Symbol (net1, net2)를 각각 정의하고, net2을 net1에 적용하는 것을 보여줍니다. 이렇게 만들어진 composed symbol은 net1과 net2의 모든 속성들을 갖습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = mx.symbol.Variable('data')\n",
    "net1 = mx.symbol.FullyConnected(data=data, name='fc1', num_hidden=10)\n",
    "\n",
    "net2 = mx.symbol.Variable('data2')\n",
    "net2 = mx.symbol.FullyConnected(data=net2, name='fc2', num_hidden=10)\n",
    "\n",
    "composed = net2(data2=net1, name='composed')\n",
    "composed.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> <font color='red'>문제</font>\n",
    "위 코드에서 정의한 network (net1, net2, composed)를 mx.viz.plot_network() 함수를 사용해서 시간화 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mx.viz.plot_network(__여기를 채우세요__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "큰 네트워크를 구성하는 경우에는 공통 prefix를 symbol에 적용해서 네트워크 구조를 알기 쉽게할 수 있습니다. 이를 위해서 `mx.name.Prefix` 함수를 아래와 같이 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.Variable(\"data\")\n",
    "net = data\n",
    "n_layer = 2\n",
    "for i in range(n_layer):\n",
    "    with mx.name.Prefix(\"layer%d_\" % (i + 1)):\n",
    "        net = mx.sym.FullyConnected(data=net, name=\"fc\", num_hidden=100)\n",
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color='blue'>Modularized Construction for Deep Networks</font>\n",
    "\n",
    "Constructing a *deep* network layer by layer, (like the Google Inception network),\n",
    "can be tedious owing to the large number of layers.\n",
    "So, for such networks, we often modularize the construction.\n",
    "\n",
    "For example, in Google Inception network,\n",
    "we can first define a factory function which chains the convolution,\n",
    "batch normalization and rectified linear unit (ReLU) activation layers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0),name=None, suffix=''):\n",
    "    conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=kernel,\n",
    "                  stride=stride, pad=pad, name='conv_%s%s' %(name, suffix))\n",
    "    bn = mx.sym.BatchNorm(data=conv, name='bn_%s%s' %(name, suffix))\n",
    "    act = mx.sym.Activation(data=bn, act_type='relu', name='relu_%s%s'\n",
    "                  %(name, suffix))\n",
    "    return act\n",
    "prev = mx.sym.Variable(name=\"Previous Output\")\n",
    "conv_comp = ConvFactory(data=prev, num_filter=64, kernel=(7,7), stride=(2, 2))\n",
    "shape = {\"Previous Output\" : (128, 3, 28, 28)}\n",
    "mx.viz.plot_network(symbol=conv_comp, shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then we can define a function that constructs an inception module based on\n",
    "factory function `ConvFactory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def InceptionFactoryA(data, num_1x1, num_3x3red, num_3x3, num_d3x3red, num_d3x3,\n",
    "                      pool, proj, name):\n",
    "    # 1x1\n",
    "    c1x1 = ConvFactory(data=data, num_filter=num_1x1, kernel=(1, 1), name=('%s_1x1' % name))\n",
    "    # 3x3 reduce + 3x3\n",
    "    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=('%s_3x3' % name), suffix='_reduce')\n",
    "    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), name=('%s_3x3' % name))\n",
    "    # double 3x3 reduce + double 3x3\n",
    "    cd3x3r = ConvFactory(data=data, num_filter=num_d3x3red, kernel=(1, 1), name=('%s_double_3x3' % name), suffix='_reduce')\n",
    "    cd3x3 = ConvFactory(data=cd3x3r, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=('%s_double_3x3_0' % name))\n",
    "    cd3x3 = ConvFactory(data=cd3x3, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=('%s_double_3x3_1' % name))\n",
    "    # pool + proj\n",
    "    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=('%s_pool_%s_pool' % (pool, name)))\n",
    "    cproj = ConvFactory(data=pooling, num_filter=proj, kernel=(1, 1), name=('%s_proj' %  name))\n",
    "    # concat\n",
    "    concat = mx.sym.Concat(*[c1x1, c3x3, cd3x3, cproj], name='ch_concat_%s_chconcat' % name)\n",
    "    return concat\n",
    "prev = mx.sym.Variable(name=\"Previous Output\")\n",
    "in3a = InceptionFactoryA(prev, 64, 64, 64, 64, 96, \"avg\", 32, name=\"in3a\")\n",
    "mx.viz.plot_network(symbol=in3a, shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, we can obtain the whole network by chaining multiple inception\n",
    "modules. See a complete example\n",
    "[here](https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbols/inception-bn.py).\n",
    "\n",
    "### <font color='blue'>Group Multiple Symbols</font>\n",
    "\n",
    "To construct neural networks with multiple loss layers, we can use\n",
    "`mxnet.sym.Group` to group multiple symbols together. The following example\n",
    "groups two outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = mx.sym.Variable('data')\n",
    "fc1 = mx.sym.FullyConnected(data=net, name='fc1', num_hidden=128)\n",
    "net = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "out1 = mx.sym.SoftmaxOutput(data=net, name='softmax')\n",
    "out2 = mx.sym.LinearRegressionOutput(data=net, name='regression')\n",
    "group = mx.sym.Group([out1, out2])\n",
    "group.list_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## NDArray와 관계\n",
    "\n",
    "`NDArray`의 장점:\n",
    "\n",
    "- Straightforward.\n",
    "- Easy to work with native language features (for loop, if-else condition, ..)\n",
    "  and libraries (numpy, ..).\n",
    "- Easy step-by-step code debugging.\n",
    "\n",
    "`Symbol`의 장점::\n",
    "\n",
    "- Provides almost all functionalities of NDArray, such as `+`, `*`, `sin`,\n",
    "  `reshape` etc.\n",
    "- Easy to save, load and visualize.\n",
    "- Easy for the backend to optimize the computation and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Symbol 조작하기\n",
    "\n",
    "`NDArray`와 비교해서 `Symbol`의 가장 중요한 차이점은, 연산을 먼저 정의하고, 데이터를 연산에 할당해서 실행한다는 것입니다. 다음 예제들에서는 Symbol을 직접 조작하는 방법을 소개합니다. 이를 위해서 `module` 패키지를 사용합니다.\n",
    "\n",
    "### <font color='red'>모양(Shape) 와 타입(Type) Inference</font>\n",
    "\n",
    "각 Symbol의 argument, 보조 상태(auxiliary states), 및 output들을 조회할 수 있습니다. input shape과 argument 타입에 따라서, output shape이나 symbol의 타입이 어떻게 되는지 유추해보는 예제는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "arg_name = c.list_arguments()  # get the names of the inputs\n",
    "out_name = c.list_outputs()    # get the names of the outputs\n",
    "# infers output shape given the shape of input arguments\n",
    "arg_shape, out_shape, _ = c.infer_shape(a=(2,3), b=(2,3))\n",
    "# infers output type given the type of input arguments\n",
    "arg_type, out_type, _ = c.infer_type(a='float32', b='float32')\n",
    "print({'input' : dict(zip(arg_name, arg_shape)),'output' : dict(zip(out_name, out_shape))})\n",
    "print({'input' : dict(zip(arg_name, arg_type)),'output' : dict(zip(out_name, out_type))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color='red'>데이터 Bind과 수행</font>\n",
    "\n",
    "Symbol `c`는 `a` + `b`를 정의하고 있습니다. 이를 계산하기 위해서는 argument들에 데이터를 바인딩해야 합니다. 바인딩은 `bind` 함수에 device context로 원하는 디바이스(CPU, GPU)를 지정하고 각 변수를 `NDArray`에 매핑하는 `dict`를 전달하고, 그 결과로 executor를 리턴받습니다. executor의 `forward` 함수를 수행해서 연산을 실행하고, `outputs` 속성을 통해서 모든 결과들을 조회합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex = c.bind(ctx=mx.cpu(), args={'a' : mx.nd.ones([2,3]),\n",
    "                                'b' : mx.nd.ones([2,3])})\n",
    "ex.forward()\n",
    "print('number of outputs = %d\\nthe first output = \\n%s' % (\n",
    "           len(ex.outputs), ex.outputs[0].asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "동일한 Symbol에 다른 데이터를 연결(binding)해서 GPU 자원에서 수행하는 것도 가능합니다.\n",
    "\n",
    "> <font color='red'>문제</font>\n",
    "다음 코드는 CPU에서 수행됩니다. GPU에서 연산이 수행되도록 변경해보세요. (힌트 mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "compute_device=mx.cpu()\n",
    "\n",
    "ex_gpu = c.bind(ctx=compute_device, args={'a' : mx.nd.ones([3,4], gpu_device)*2,\n",
    "                                      'b' : mx.nd.ones([3,4], gpu_device)*3})\n",
    "ex_gpu.forward()\n",
    "ex_gpu.outputs[0].asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`eval` 함수를 통해서 symbol을 evaluate할 수도 있습니다. `eval` 함수는 `bind` 함수와 `forward` 함수를 함께 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex = c.eval(ctx = mx.cpu(), a = mx.nd.ones([2,3]), b = mx.nd.ones([2,3]))\n",
    "print('number of outputs = %d\\nthe first output = \\n%s' % (\n",
    "            len(ex), ex[0].asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Neural network에서 모든 argument 배열을 자동으로 생성해주는 ```simple_bind``` 함수도 많이 사용됩니다. ```simple_bind```를 호출한 후, ```forward```를 호출해서 결과를 계산하거나, 필요한 경우 ```backward``` 함수를 호출해서 gradient를 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color='red'>Load and Save</font>\n",
    "\n",
    "Logically symbols correspond to ndarrays. Symbol와 NDArray는 tensor를 표현하고, 연산의 입력 또는 출력에 사용됩니다. 이후 사용을 위해서, `Symbol` 객체는 `pickle` 또는 `save`/`load` 함수를 이용해서 serialize한 후 파일에 저장하고 다시 읽어올 수 있습니다.\n",
    "\n",
    "`NDArray`를 serialize하면, tensor 데이터가 직렬화되고, 바이너리 형태로 디스크에 저장됩니다.\n",
    "\n",
    "하지만, Symbol은 연산들을 채인으로 구성된 그래프를 표한하고 있습니다. 이 그래프는 output symbol로 표현됩니다. `Symbol`을 직렬화하면, 해당 symbol이 output인 그래프를 직렬화합니다. 직렬화된 내용은 읽기 쉬운 `json` 형식으로 변경되며, `tojson` 함수를 이용해서 `json` 문자열로 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(c.tojson())\n",
    "c.save('symbol-c.json')\n",
    "c2 = mx.sym.load('symbol-c.json')\n",
    "c.tojson() == c2.tojson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Customized Symbol\n",
    "\n",
    "Most operators such as `mx.sym.Convolution` and `mx.sym.Reshape` are implemented\n",
    "in C++ for better performance. MXNet also allows users to write new operators\n",
    "using any front-end language such as Python. It often makes the developing and\n",
    "debugging much easier. To implement an operator in Python, refer to\n",
    "[How to create new operators](http://mxnet.io/how_to/new_op.html).\n",
    "\n",
    "## Advanced Usages\n",
    "\n",
    "### <font color='blue'>Type Cast</font>\n",
    "\n",
    "By default, MXNet uses 32-bit floats.\n",
    "But for better accuracy-performance,\n",
    "we can also use a lower precision data type.\n",
    "For example, The Nvidia Tesla Pascal GPUs\n",
    "(e.g. P100) have improved 16-bit float performance,\n",
    "while GTX Pascal GPUs (e.g. GTX 1080) are fast on 8-bit integers.\n",
    "\n",
    "To convert the data type as per the requirements,\n",
    "we can use `mx.sym.cast` operator as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = mx.sym.Variable('data')\n",
    "b = mx.sym.cast(data=a, dtype='float16')\n",
    "arg, out, _ = b.infer_type(data='float32')\n",
    "print({'input':arg, 'output':out})\n",
    "\n",
    "c = mx.sym.cast(data=a, dtype='uint8')\n",
    "arg, out, _ = c.infer_type(data='int32')\n",
    "print({'input':arg, 'output':out})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### <font color='blue'>Variable Sharing</font>\n",
    "\n",
    "To share the contents between several symbols,\n",
    "we can bind these symbols with the same array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = mx.sym.Variable('a')\n",
    "b = mx.sym.Variable('b')\n",
    "b = a + a * a\n",
    "\n",
    "data = mx.nd.ones((2,3))*2\n",
    "ex = b.bind(ctx=mx.cpu(), args={'a':data, 'b':data})\n",
    "ex.forward()\n",
    "ex.outputs[0].asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
